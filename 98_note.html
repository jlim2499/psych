<div id="div_notes"><link href="style2.css" rel="stylesheet"/><br/><h4 id="notetitle" style="color: #1a9cce;">Stats (ROC curves)<span id="note_star_span"></span></h4><br/><div id="notecontent">ROC (receiver operating characteristic) curves are used to tell how good a test is at distinguishing between two things (e.g. which patients have a disease and which don't), and to help decide on the threshold that should be used.<br/><br/><i>The whole point of an ROC curve is to help you decide where to draw the line between normal and not normal.</i><br/><br/>ROC analysis is useful to: <br/><br/><ul><li>evaluate the discriminatory ability of a continuous marker to correctly assign into a two-group classification</li><li>find an optimal cut-off point to least mis-classify the two-group subjects</li><li>compare the efficacy of two (or more) diagnostic tests or markers</li><li>study the inter-observer variability when two or more observers measure the same continuous variable</li></ul><br/><i>(In psychiatry, ROC curves are usually used to assess the performance and utility of diagnostic / screening tools).</i><br/><br/>When a test is used, there is always a trade off between sensitivity and specificity. The threshold (or cut-off) used to discriminate whether the result is positive or negative can be changed to get the right balance of the two.<br/><br/>An example is the CAGE questionnaire used to screen for alcohol dependence, which uses 4 questions. If the cut off for probable alcohol dependence is only one positive question then the test would be very sensitive (would pick up most of those with alcohol dependence) but would not be very specific (as lots of people without alcohol dependence would be identified). Conversely, if a cut-off was 4 positive questions then the test would have low sensitivity (some people with alcohol dependence would be missed) but the specificity would be high.<br/><br/>A ROC curve is created by plotting the true positive rate against the false positive rate at various threshold settings (see below). This is done plotting sensitivity (true positive rate) against 1-specificity (false positive rate).<br/><br/><center><table><tbody><tr><td align="left" colspan="2"><img class="ajaximage" src="https://d3a7z3xcyhqwt4.cloudfront.net/images_MRCPsychmentor/mma018.png"/></td></tr><tr><td align="left" valign="top"></td><td align="right"></td></tr></tbody></table></center><br/>The black dots on the curve represent different thresholds (or cut-off points).<br/><br/>The dot closest to the top left hand corner is the one with the best trade off between sensitivity and specificity.<br/><br/><b>It's always a trade off</b><br/><br/>The cut off value is used to indicate if a disease / condition is present or absent. There is usually some overlap though and so there is often a decision to be made as to where to put the cut off. From the image below it can be seen that the cut off point results in some people without the disease being identified as having it. <br/><br/><center><table><tbody><tr><td align="left" colspan="2"><a class="fancybox" data-fancybox="" href="https://d3a7z3xcyhqwt4.cloudfront.net/images_MRCPsychmentor/mmb035b.png" rel="group"><img class="ajaximage" src="https://d3a7z3xcyhqwt4.cloudfront.net/images_MRCPsychmentor/mmb035.png"/></a></td></tr><tr><td align="left" valign="top"></td><td align="right"><a class="fancybox lbmagglasslink" data-fancybox="" href="https://d3a7z3xcyhqwt4.cloudfront.net/images_MRCPsychmentor/mmb035b.png" rel="group"><img src="https://d3a7z3xcyhqwt4.cloudfront.net/css/images/mag_glass.png"/></a></td></tr></tbody></table></center><br/>If the cut off is moved to the right than there will be less false positives (FP) but also less true positives (TP). This is the theoretical basis for the need for a ROC curve. <br/><br/><b>AUC (area under the curve)</b><br/><br/>If a test had a sensitivity of 1 (100% sensitive) and a specificity of 1 (100% specific) then the area under the curve would be 1. Therefore, it follows that the higher the AUC is the better the overall performance of the test (i,e. the higher the accuracy).<br/><br/>The following table illustrates the conventional grading of AUCs:<br/><br/><div class="table-responsive"><table class="tlarge table table-striped table-bordered" data-role="table" id="tableid1"><thead><tr><th>AUC value</th><th>Quality</th></tr></thead><tbody><tr><td>0.9-1</td><td>Excellent</td></tr><tr><td>0.8-0.9</td><td>Good</td></tr><tr><td>0.7-0.8</td><td>Fair</td></tr><tr><td>0.6-0.7</td><td>Poor</td></tr><tr><td>0.5-0.6</td><td>Fail</td></tr></tbody></table></div></div></div>