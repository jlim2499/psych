<div id="div_question"><link href="style1.css" rel="stylesheet"/>Which of the following is true regarding statistical power?<br/><div><br/><span style="background-color: #A5FF7F; padding: 11px 22px; border-radius: 4px; border-left: 5px solid green;">The larger the sample size of a study the greater the power</span></div><br/>The correct answer is '<b>The larger the sample size of a study the greater the power</b>'. The statistical power of a study refers to the probability that it will correctly reject a false null hypothesis (i.e., detect an effect when one exists). In simpler terms, it's the ability of a test to find an effect if there is one. This is directly related to sample size - as the number of participants in a study increases, so does the likelihood that any observed effect is not due to chance, thereby increasing the power.<br/><br/>Now let's consider each of the incorrect options:<br/><br/>'<b>The power of a study is equivalent to the type I error</b>' - This statement is incorrect. Type I error, also known as alpha or false positive rate, refers to rejecting a true null hypothesis. It represents finding an effect where none actually exists. Power and type I error are related but not equivalent; increasing power often involves accepting a higher rate of Type I errors.<br/><br/>'<b>Power is a measure of a studies ability to change clinical practice</b>' - While powerful studies can indeed influence clinical practice by providing strong evidence for or against certain interventions, saying that power measures this ability oversimplifies its purpose and role in research design. Power primarily relates to statistical significance and not directly to clinical relevance or applicability.<br/><br/>'<b>Power can assume any value from -1 to 1</b>' - This statement misrepresents how power is quantified. Power ranges from 0 (no chance of detecting an effect) to 1 (certainty of detecting an effect), but cannot take negative values.<br/><br/>'<b>The term power is synonymous with the term significance</b>' - While these two concepts are closely linked in statistical analysis, they are not interchangeable. Significance typically refers specifically to whether or not an observed result could have occurred by chance (usually at a threshold of p&lt;0.05), while power relates more broadly to the ability of a test to detect an effect if one exists.<br/></div>