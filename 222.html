<div id="div_question"><link href="style1.css" rel="stylesheet"/>Which of the following statements is true regarding Type I error in hypothesis testing?<br/><div><br/><span style="background-color: #A5FF7F; padding: 11px 22px; border-radius: 4px; border-left: 5px solid green;">It occurs when a true null hypothesis is incorrectly rejected</span></div><br/>The correct answer is <b>It occurs when a true null hypothesis is incorrectly rejected</b>. A Type I error happens when the null hypothesis (which is actually true) is rejected, leading to a false positive result. In other words, it is the incorrect conclusion that an effect or difference exists when it actually does not.<br/><br/><b>It is also known as a beta error</b>: This is incorrect. A beta error refers to a Type II error, which occurs when the null hypothesis is falsely accepted (failing to detect a true effect or difference).<br/><br/><b>Increasing the sample size increases the risk of Type I error</b>: This is incorrect. Sample size does not directly affect the risk of Type I error, as this risk is determined by the significance level (alpha) set by the researcher. However, a larger sample size increases the study's power and reduces the risk of a Type II error.<br/><br/><b>Setting a lower significance level (alpha) increases Type I error</b>: This is incorrect. Lowering the alpha (e.g., from 0.05 to 0.01) decreases the likelihood of a Type I error because the threshold for rejecting the null hypothesis becomes more stringent.<br/><br/><b>It is unaffected by multiple comparisons</b>: This is incorrect. Multiple comparisons increase the likelihood of committing a Type I error unless statistical corrections (e.g., Bonferroni correction) are applied. Without these corrections, the risk of false positives accumulates with each additional test.<br/></div>