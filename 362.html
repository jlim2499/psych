<div id="div_question"><link href="style1.css" rel="stylesheet"/><b>Theme: </b>Hypothesis testing<br/><br/><table><tbody><tr><td><b>A.</b></td><td>P value</td></tr><tr><td><b>B.</b></td><td>Null hypothesis</td></tr><tr><td><b>C.</b></td><td>Type one error</td></tr><tr><td><b>D.</b></td><td>Power</td></tr><tr><td><b>E.</b></td><td>Type two error</td></tr><tr><td><b>F.</b></td><td>Alternative hypothesis</td></tr></tbody></table><br/><br/>Match the following definitions to the above terms.<br/><br/><table class="qbody" style="width:100%"><tbody><tr><td style="vertical-align: top;width:35px"><b>438.</b></td><td>Occurs when the null hypothesis is accepted when it is false</td></tr><tr><td></td><td><b>Type two error</b> A type II error occurs when the null hypothesis is accepted when it is false (failing to find a difference that really existed), this is also called a false negative. </td></tr></tbody></table><br/><br/><table class="qbody" style="width:100%"><tbody><tr><td style="vertical-align: top;width:35px"><b>439.</b></td><td>1 - the probability of a type II error</td></tr><tr><td></td><td><b>Power</b> The power of a statistical test is a crucial concept in hypothesis testing. It represents the probability of correctly rejecting a false null hypothesis, which is essentially the test's ability to detect a true effect when it exists. In mathematical terms, it's defined as:<br/><br/>Power = 1 - Probability of Type II Error<br/><br/>A high power value is desirable because it means that the test is more likely to identify a real difference or effect if it's present in the data.<br/><br/>Alpha (Î±): This is the significance level or the probability of making a Type I error. In hypothesis testing, you set a threshold (typically 0.05 in medical research) for alpha. If the p-value from your test is less than or equal to alpha, you reject the null hypothesis.<br/><br/>Beta (Î²): Beta represents the probability of making a Type II error. A Type II error occurs when you fail to reject the null hypothesis when it is false, meaning you miss detecting a true effect or difference. Beta is dependent on the effect size (the magnitude of the difference you're trying to detect) and the sample size. A smaller beta indicates a more powerful test because it means a lower probability of missing a true effect.<br/><br/>Power (1 - Î²): Power is the complement of beta, and it quantifies the probability of correctly rejecting the null hypothesis when it is false. In other words, it measures the test's ability to identify a real effect. High power is desirable because it means you're more likely to detect true effects when they exist.</td></tr></tbody></table><br/><br/><table class="qbody" style="width:100%"><tbody><tr><td style="vertical-align: top;width:35px"><b>440.</b></td><td>Occurs when the null hypothesis is rejected when it is true</td></tr><tr><td></td><td><b>Type one error</b> A type I error occurs when the null hypothesis is rejected when it is true (finding a difference that didn't exist), this is also called a false positive.</td></tr></tbody></table><br/><br/></div>