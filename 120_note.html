<div id="div_notes"><link href="style2.css" rel="stylesheet"/><br/><h4 id="notetitle" style="color: #1a9cce;">Stats (validity)<span id="note_star_span"></span></h4><br/><div id="notecontent">Validity refers to the extent to which something measures what it claims to measure.  The first major distinction is between internal and external validity.<br/><br/>Note: Reliability and validity are not the same. Reliability is the extent to which an experiment, test, or any measuring procedure yields the same result on repeated trials. <br/><br/><div class="table-responsive"><table class="tlarge table table-striped table-bordered" data-role="table" id="tableid1"><thead><tr><th></th><th></th></tr></thead><tbody><tr><td>Internal validity</td><td>Internal validity is the confidence that we can place in the cause and effect relationship in a study. It is the confidence that we have that the change in the independent variable caused the observed change in the dependent variable (rather than due to poor control of extraneous variables)<br/><br/>Threats to internal validity:<br/><br/><ul><li>Reliability of measurement instruments</li><li>Regression towards the mean (subjects selected based on extreme scores will tend to regress spontaneously towards the mean on subsequent tests)</li><li>Sampling</li><li>Experimental mortality (loss of participants over time may result in unequal characteristics in two groups)</li><li>Instrument obtrusiveness (the instrument should not affect the data collection e.g. poorly designed questionnaires)</li><li>Manipulation effectiveness (the independent variable must be manipulated enough so that the effect can be seen, ideally the degree of manipulation should be measured)</li><li>History (where two measurements of the dependent variable occur that are separated in time, there is the potential for various other influences to get introduced)</li><li>Maturation (people mature over time and this may in itself explain the change of a dependent variable)</li><li>Measurement sensitisation (the instrument may affect the way the subject see's the world and so may bias future measures)</li><li>Measurement instrument learning  (people may get used to the measurement instrument, a good example is the increasing performance on repeated use of the WAIS for estimation of IQ)</li></ul></td></tr><tr><td>External validity</td><td>External validity is the degree to which the conclusions in a study would hold for other persons in other places and at other times, i.e. its ability to generalise.<br/><br/><br/>Threats to external validity:<br/><br/><ul><li>Representativeness of the sample</li><li>Reactive effects of setting (is the research setting artificial)</li><li>Effect of testing (if a pre-test was used in the study that will not be used in the real world this may affect outcomes)</li><li>Multiple treatment inference (this refers to study's in which subject receive more than one treatment, the effects of multiple treatments may interact)</li></ul></td></tr></tbody></table></div><br/>There are several other types of validity (see table)<br/><br/><div class="table-responsive"><table class="tlarge table table-striped table-bordered" data-role="table" id="tableid2"><thead><tr><th><b>Validity subtype</b></th><th><b>Description</b></th></tr></thead><tbody><tr><td>Face validity</td><td>Face validity refers to the general impression of a test.  A test has face validity if it appears to test what it is meant to</td></tr><tr><td>Content validity</td><td>Content validity refers to the extent to which a test or measure assesses the full content of a subject or area.  For example if a test is designed to help diagnose depression, it would have poor content validity if it only asked about psychological symptoms and neglected biological ones</td></tr><tr><td>Criterion validity</td><td>Criterion validity concerns the comparison of tests. You may wish to compare a new test to see if it works as well as an old, accepted method. The correlation coefficient is used to test such comparisons</td></tr><tr><td>Criterion validity (Concurrent)*</td><td>In concurrent validation, the predictor and criterion data are collected at or about the same time. An example could be testing a new, shorter test of intellectual functioning against a standard measure</td></tr><tr><td>Criterion validity (Predictive)*</td><td>In Predictive validation, the predictor scores are collected first and criterion data are collected at some later/future point. Here you want to know if the test predicts future outcomes. An example might be evaluating a new assessment method to select medical students. The test could be compared against the students performance at the end of year one to see if there is a correlation</td></tr><tr><td>Construct validity</td><td>The extent to which a test measures the construct it aims to</td></tr><tr><td>Construct validity (Convergent)*</td><td>A test has convergent validity if it has a high correlation with another test that measures the same construct</td></tr><tr><td>Construct validity (Divergent)*</td><td>A test's divergent validity is demonstrated through a low correlation with a test that measures a different construct</td></tr></tbody></table></div><br/>* Note that concurrent and predictive validity are subcategories of criterion validity and that convergent and divergent validity are subcategories of construct validity.</div></div>