<div id="div_notes"><link href="style2.css" rel="stylesheet"/><br/><h4 id="notetitle" style="color: #1a9cce;">Stats (power)<span id="note_star_span"></span></h4><br/><div id="notecontent">The power of a study refers to the probability of correctly rejecting the null hypothesis when it is false (i.e., detecting a real effect and avoiding a Type II error). In other words, it represents the study's ability to identify a true difference or effect when one actually exists.<br/><br/>The concept of power is critical in designing studies, as it helps determine the sample size required to detect a clinically meaningful difference or effect with a high level of confidence.<br/><br/>Key Features of Power:<br/><br/><ul><li>Range: Power ranges from 0 to 1, as it is a probability. It is often expressed as a percentage: 0 equates to 0%, while 1 corresponds to 100%.</li><li>Formula: Power = 1 - beta, where beta is the probability of making a Type II error (failing to reject the null hypothesis when it is false).</li><li>Acceptable Levels: A power of 0.80 (or 80%) is often considered the minimum acceptable threshold in clinical research. This means there is an 80% chance of detecting a true effect and only a 20% chance of making a Type II error.</li></ul><br/>Factors Influencing Power:<br/><br/><ul><li>Sample Size:</li></ul><br/>Larger sample sizes reduce the variance of parameter estimates, increasing the study's ability to detect significant effects.<br/><br/>For example, in a study comparing the efficacy of two antipsychotics, a larger sample size ensures that smaller yet clinically meaningful differences in symptom reduction are more likely to be identified.<br/><br/><ul><li>Effect Size:</li></ul><br/>The meaningful effect size is the magnitude of the difference or association that the study aims to detect. It must be defined a priori during study planning.<br/><br/>Larger effect sizes are easier to detect, requiring smaller sample sizes, whereas smaller effect sizes demand larger samples.<br/><br/>Clinically, this could refer to the difference in relapse rates between patients receiving standard care versus a novel intervention.<br/><br/><ul><li>Significance Level (Alpha):</li></ul><br/>The significance level, or alpha, is the probability of making a Type I error (incorrectly rejecting the null hypothesis). Commonly set at 0.05, it determines the threshold for statistical significance.<br/><br/>Reducing alpha (e.g., to 0.01) decreases the likelihood of Type I error but also lowers the power unless compensated for with a larger sample size.<br/><br/>Practical Implications:<br/><br/>In psychiatric research, underpowered studies are common due to the difficulty of recruiting large samples, particularly in rare conditions or specialised populations.<br/><br/>For example, a trial on treatment-resistant schizophrenia must balance the need for adequate power with the feasibility of enrolling a sufficient number of participants.<br/><br/>When planning or interpreting research, psychiatrists should critically evaluate whether the study had adequate power to detect clinically meaningful effects, as underpowered studies are at high risk of producing inconclusive or misleading results.</div></div>