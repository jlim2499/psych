<div id="div_notes"><link href="style2.css" rel="stylesheet"/><br/><h4 id="notetitle" style="color: #1a9cce;">Stats (measures of dispersion)<span id="note_star_span"></span></h4><br/><div id="notecontent">Dispersion is an indication as to how much variation or spread there is across a data set. It is usually used in conjunction with a measure of central tendency, such as the mean or median, to provide an overall description of a set of data.<br/><br/><b>Range and interquartile range</b><br/><br/><center><table><tbody><tr><td align="left" colspan="2"><img class="ajaximage" src="https://d3a7z3xcyhqwt4.cloudfront.net/images_MRCPsychmentor/mma053.png"/></td></tr><tr><td align="left" valign="top"></td><td align="right"></td></tr></tbody></table></center><br/>Range:<br/><br/>The simplest measure of dispersion is the range, which is the difference between the largest and smallest value.  <br/><br/>Interquartile range:<br/><br/>The Interquartile range (also called the mid spread) is equal to the difference between the 3rd and 1st quartiles.<br/><br/>The median divides the data into two halves. For a set of n ordered numbers the median is the (n + 1) Ã· 2 th value. In this case n = 11 so it is the 6th value.<br/><br/><div class="table-responsive"><table class="tlarge table table-striped table-bordered" data-role="table" id="tableid1"><thead><tr><th>n</th><th>Value</th></tr></thead><tbody><tr><td>1</td><td>62</td></tr><tr><td>2</td><td>65</td></tr><tr><td><b>3</b></td><td><b>67</b> <i>(Q1 or lower quartile)</i></td></tr><tr><td>4</td><td>71</td></tr><tr><td>5</td><td>72</td></tr><tr><td><b>6</b></td><td><b>74</b> <i>(Q2 or median)</i></td></tr><tr><td>7</td><td>74</td></tr><tr><td>8</td><td>88</td></tr><tr><td><b>9</b></td><td><b>89</b> <i>(Q3 or Upper quartile)</i></td></tr><tr><td>10</td><td>108</td></tr><tr><td>11</td><td>125</td></tr></tbody></table></div><br/>The 1st quartile divides the bottom half of the data into two halves, and the 3rd quartile divides the upper half of the data into two halves.<br/><br/>The 1st quartile (equal to the 25th percentile of the data) is the (n + 1) Ã· 4 th value. Which in this case is number 3 which is 67.<br/><br/>The 3rd quartile (equal to the 75th percentile of the data) is the 3 (n + 1) Ã· 4 th value. Which in this case is number 9 which is 89.<br/><br/>The interquartile range of this data set would therefore be 89 - 67 (Q3 - Q1) which is 22 <br/><br/><i>Note: A percentile (or a centile) is a measure used in statistics indicating the value below which a given percentage of observations in a group of observations fall. For example, the 20th percentile is the value (or score) below which 20% of the observations may be found.</i> <br/><br/>Since quartile divide a data set into quarters we can make some additional comments about the data.<br/><br/><ul><li>75% of the data set is below Q3</li><li>50% of the data set is less than Q2</li><li>25% of the data set is below Q1</li><li>50% of the data set is between Q1 and Q3</li></ul><br/>Quartiles and ranges are useful, but they are also somewhat limited because they do not take into account every score in our group of data. To get a more representative idea of spread we need to take into account the actual values of each score in a data set. The variance and standard deviation are such measures.<br/><br/>Formulas for Quartiles: Positional vs Percentile Methods<br/><br/>Positional Method:<br/><br/>The positional method involves ordering the data set and then using the position of data points to determine the quartiles.<br/><br/>Steps:<br/><br/><ul><li>1) Order the Data: Arrange the data in ascending order.</li><li>2) Calculate Quartiles:<ul><li>First Quartile (Q1): The position of Q1 is given by ( (n + 1) / 4), where n is the number of observations.</li><li>Second Quartile (Q2) or Median: The position of Q2 is given by ( (n + 1) / 2).</li><li>Third Quartile (Q3): The position of Q3 is given by ( 3(n + 1) / 4).</li></ul></li></ul><br/>Percentile Method:<br/><br/>The percentile method calculates quartiles as specific percentiles of the data set.<br/><br/>Steps:<br/><br/><ul><li>Order the Data: Arrange the data in ascending order.</li><li>Calculate Percentiles:<ul><li>First Quartile (Q1): The 25th percentile, where Q1 is the value below which 25% of the data fall.</li><li>Second Quartile (Q2) or Median: The 50th percentile, where Q2 is the value below which 50% of the data fall.</li><li>Third Quartile (Q3): The 75th percentile, where Q3 is the value below which 75% of the data fall.</li></ul></li></ul><br/>Both methods are valuable and applicable in different contexts depending on the level of precision required and the nature of the data set.<br/><br/><b>Variance</b><br/><br/><center><table><tbody><tr><td align="left" colspan="2"><img class="ajaximage" src="https://d3a7z3xcyhqwt4.cloudfront.net/images_MRCPsychmentor/mma054.png"/></td></tr><tr><td align="left" valign="top"></td><td align="right"></td></tr></tbody></table></center><br/>The variance gives an indication as to the amount the items in the data set vary from the mean. <br/><br/>It is a measure of dispersion that describes the relative distance between the data points in the set and the mean of the data set.<br/><br/>It is calculated by the following formula:<br/><br/><center><table><tbody><tr><td align="left" colspan="2"><a class="fancybox" data-fancybox="" href="https://d3a7z3xcyhqwt4.cloudfront.net/images_MRCPsychmentor/mmb192b.png" rel="group"><img class="ajaximage" src="https://d3a7z3xcyhqwt4.cloudfront.net/images_MRCPsychmentor/mmb192.png"/></a></td></tr><tr><td align="left" valign="top"></td><td align="right"><a class="fancybox lbmagglasslink" data-fancybox="" href="https://d3a7z3xcyhqwt4.cloudfront.net/images_MRCPsychmentor/mmb192b.png" rel="group"><img src="https://d3a7z3xcyhqwt4.cloudfront.net/css/images/mag_glass.png"/></a></td></tr></tbody></table></center><br/><i>Note: For sample variance use n-1 as the denominator whereas for population variance use N.</i><br/><br/>As a measure of variability, the variance is useful. If the scores in a group of data are spread out, the variance will be a large number. Conversely, if the scores are spread closely around the mean, the variance will be a smaller number. <br/><br/>There are two potential problems with the variance. First, because the deviations of scores from the mean are 'squared' (this is done to deal with the negative values), this gives more weight to extreme scores. If our data contains outliers, this can give undo weight to these scores. Secondly, the variance is not in the same units as the scores in our data set (variance is measured in the units squared). This means we cannot place it on our frequency distribution and cannot directly relate its value to the values in our data set. Calculating the standard deviation rather than the variance rectifies this problem.                                                      <br/><br/><b>Standard deviation (SD)</b><br/><br/>The SD is used to reflect the distribution of individual scores around their mean.  It indicates how the data varies. It is a descriptive statistic used to describe a sample or population (it is not the same as the standard error of the mean, see below).<br/><br/>To calculate it simply take the square root of the variance.<br/><br/>A low standard deviation indicates that data points tend to be very close to the mean.  <br/><br/><center><table><tbody><tr><td align="left" colspan="2"><img class="ajaximage" src="https://d3a7z3xcyhqwt4.cloudfront.net/images_MRCPsychmentor/mma055.png"/></td></tr><tr><td align="left" valign="top"></td><td align="right"></td></tr></tbody></table></center><br/>Unlike the variance, the standard deviation is expressed in the same units as the data set. <br/><br/>SDs can be used to indicate how confident we are that data points lie within a particular range (this is however different to a confidence interval (CI) see below).<br/><br/><center><table><tbody><tr><td align="left" colspan="2"><img class="ajaximage" src="https://d3a7z3xcyhqwt4.cloudfront.net/images_MRCPsychmentor/mma056.png"/></td></tr><tr><td align="left" valign="top"></td><td align="right"></td></tr></tbody></table></center><br/>For example. If we did a study on the IQ of MRCPsych candidates we would calculate a mean (hopefully above 100), and we could also calculate a standard deviation (by a complicated formula that you do not need to know for the exams).<br/><br/>Using the standard deviation we could then say that we would expect that...<br/><br/>A range of one SD above and below the mean would include 68.2% of the values from the study.<br/><br/>A range of two SDs above and below the mean would include 95.4% of the values from the study.<br/><br/>A range of three SDs above and below the mean include 99.7% of the values from the study.<br/><br/>A few things to note about the standard deviation:<br/><br/><ul><li>It can never be negative</li><li>The smallest value it can have is 0 (a SD of zero tells you that all the values are the same)</li><li>It is affected by outliers</li><li>It has the same units as the original data</li></ul><br/><b>Standard error of the mean (SEM)</b><br/><br/>The standard error of the mean is an inferential statistic used to estimate the population mean.<br/><br/>It is a measure of the spread expected for the mean of the observations - i.e. how 'accurate' the calculated sample mean is from the true population mean<br/><br/>SEM = s / square root (n)<br/><br/>s = standard deviation of the sample mean<br/>n = sample size<br/><br/>Therefore the SEM gets smaller as the sample size (n) increases<br/><br/>On its own the SE is pretty meaningless, as its real use lies in calculating CIs when we are trying to estimate the precision of our estimate of the population mean.<br/><br/>so...<br/><br/><ul><li>The SD quantifies scatter (how much the data varies)</li><li>The SEM quantifies how precisely you know the true mean of the population</li><li>The SEM takes into account both the value of the SD and the sample size</li><li>Both SD and SEM are in the same units (the units of the data)</li><li>The SEM, by definition, cannot be larger than the SD</li><li>The SEM gets smaller as the samples get larger</li></ul><br/>A confidence interval is always quantified by a confidence level, usually expressed as a percentage (e.g. a 95% confidence interval).<br/><br/>Sample results, such as the mean value, are typically accompanied by a confidence interval. This interval indicates the precision of the sample estimate and suggests a range in which the true population mean is likely to be found. For example, if a study determines that the mean height of a sample from a population is 183 cm, with a standard error (SE) of the mean being 2 cm, then the 95% confidence interval can be calculated using the formula:<br/><br/>Confidence Interval = Mean ± (Critical Value × SE)<br/><br/>For a 95% confidence interval, the critical value used is approximately 1.96 when the sample size is large and the z-distribution is applicable. Applying this critical value, the 95% confidence interval is:<br/><br/>Lower limit = 183 - (1.96 × 2) = 179.08 cm<br/>Upper limit = 183 + (1.96 × 2) = 186.92 cm<br/><br/>After rounding these to whole numbers, the 95% confidence interval is approximately 179 cm to 187 cm. This interval implies that we can be 95% confident that the actual population mean height falls within this range. It's crucial to understand that this does not mean that the mean height from all possible samples will be within this interval 95% of the time. Instead, it means that if numerous samples were taken and a 95% confidence interval was calculated for each, about 95% of those intervals would encompass the true population mean.<br/><br/>The confidence interval is a range that is likely to contain the true value (but it won't always).<br/><br/>The following may help to clarify the difference and relationship between the SD, the SEM, and the CI:<br/><br/>Imagine you're trying to estimate the average height of people in a city. This analogy will help illustrate the differences and relationships between Standard Deviation (SD), Standard Error of the Mean (SEM), and Confidence Interval (CI).<br/><br/>Small Sample (Few People)<br/><br/><ul><li>Scenario: You measure the height of only 5 people.</li><li>SD (Standard Deviation): The individual heights might vary greatly—one person might be very tall, another very short, etc. </li><li>This high variation means the SD is large. SD measures how spread out the individual data points are from the mean.</li></ul>SEM (Standard Error of the Mean): Because you have only a few measurements, the sample mean might not be very reliable. The SEM, which quantifies how precisely the sample mean estimates the true population mean, is also high. SEM is calculated as SEM = s / square root (n) . With a small n, the SEM is larger.<br/><ul><li>CI (Confidence Interval): The CI gives a range within which we expect the true population mean to lie. With a high SEM, the CI will be wide, indicating less confidence that the sample mean is close to the true population mean.</li></ul><br/>Large Sample (Many People)<br/><br/><ul><li>Scenario: You measure the height of 10,000 people.</li><li>SD (Standard Deviation): There might still be a lot of variation in individual heights (high SD), but because you have so many measurements, the average height of this large group is likely to be close to the true average height of the city's population.</li><li>SEM (Standard Error of the Mean): With a large sample size, the SEM is very low. Even with a high SD, the formula </li></ul>SEM = s / square root (n) shows that increasing n (sample size) reduces the SEM significantly. This means the sample mean is a very precise estimate of the true population mean.<br/><ul><li>CI (Confidence Interval): The CI will be narrow because the SEM is low. A narrow CI indicates high confidence that the sample mean is close to the true population mean.</li></ul><br/>Summary<br/><br/><ul><li>Standard Deviation (SD): Measures the variability or spread of individual data points. It reflects how diverse the heights are in your sample.</li><li>Standard Error of the Mean (SEM): Measures the precision of the sample mean as an estimate of the population mean. A smaller SEM indicates a more precise estimate, and it decreases as the sample size increases.</li><li>Confidence Interval (CI): Uses the SEM to provide a range around the sample mean within which we expect the true population mean to lie. A larger sample size results in a smaller SEM and a narrower CI, indicating greater confidence in the accuracy of the sample mean.</li></ul><br/>Common Sense Key Points<br/><br/><ul><li>Small Sample: High SD, high SEM, wide CI. Less confidence in the sample mean as an estimate of the population mean.</li><li>Large Sample: High SD, low SEM, narrow CI. More confidence in the sample mean as an estimate of the population mean.</li></ul>In essence, the larger the sample size, the more precise our estimate of the population mean becomes, resulting in a lower SEM and a narrower CI, even if individual data points (heights) vary widely.</div></div>