<div id="div_notes"><link href="style2.css" rel="stylesheet"/><br/><h4 id="notetitle" style="color: #1a9cce;">Stats (correlation and regression)<span id="note_star_span"></span></h4><br/><div id="notecontent"><b>Correlation</b> <br/><br/>The terms correlation and regression are related but are not synonymous.  Correlation is used to test for association between variables (e.g. whether salary and IQ are related).  Once correlation between two variables has been shown regression can be used to predict values of other dependent variables from independent variables.  Regression is not used unless two variables have firstly been shown to correlate. <br/><br/>Correlation can be classified into three basic categories: <br/><br/><ul><li>Linear </li><li>Non-linear </li><li>No correlation </li></ul><br/>Variables that are correlated through a linear relationship can display either positive or negative correlation. Positively correlated variables vary directly (as one increases so does the other). Negatively correlated variables vary as opposites (as the value of one variable increases the other decreases). <br/><br/>Correlation may be: <br/><br/><ul><li>Strong </li><li>Moderate </li><li>Weak </li></ul><br/>The strength of the association can be estimated by observing a scatter graph of the variables (see below). The correlation type is independent of the strength. <br/><br/>The strength of a linear relationship is measured by the correlation coefficient (Pearson's correlation coefficient). The sample correlation coefficient is given the symbol r. The population correlation coefficient has the symbol ρ (rho).  <br/><br/>The sign of the correlation coefficient tells us the direction of the linear relationship. If r is negative (&lt;0) the correlation is negative and the trend line slopes down. If r is positive (&gt; 0) the correlation is positive and the trend line slopes up. <br/><br/>The size (magnitude) of the correlation coefficient tells us the strength of a linear relationship (Campbell, 2021). <br/><br/><ul><li>If r = 0.8-1 this implies a very strong linear association </li><li>If r = 0.6-0.79 this implies strong correlation</li><li>If r = 0.4-0.59 this implies moderate correlation</li><li>If r = 0.2-0.39 this implies weak correlation</li><li>If r = 0-0.19 this implies a very weak linear association </li></ul><br/><i>Note: Several authors have offered guidelines for the interpretation of a correlation coefficient. However, all such criteria are in some ways arbitrary. The interpretation of a correlation coefficient depends on the context and purposes.</i><br/><br/>Correlation can suggest association but can neither prove nor disprove causation (just because two things are associated, one does not necessarily cause the other, and e.g. lung cancer may be associated with carrying matches)   <br/><br/>Correlation is summarised when using parametric variables by Pearson's correlation coefficient.  In the situation of non-parametric variables, Spearman's correlation coefficient is used.  As for Pearson's, Spearman's correlation coefficient is represented by the Greek letter p (rho), or by rs (for samples). <br/><br/>In the case of dichotomous variables logistic regression is used.  Linear (or simple linear) regression is used when looking for association between two continuous variables, and multiple regression is used when looking for association between more than two continuous variables. <br/><br/><div class="table-responsive"><table class="tlarge table table-striped table-bordered" data-role="table" id="tableid1"><thead><tr><th>Type</th><th>Used for</th><th>Symbol for sample</th><th>Symbol for population</th></tr></thead><tbody><tr><td>Pearson</td><td>Parametric</td><td>r</td><td>ρ</td></tr><tr><td>Spearman</td><td>Non-parametric</td><td>rs</td><td>ρ</td></tr></tbody></table></div><br/><b>Linear regression</b> <br/><br/>In contrast to the correlation coefficient, linear regression may be used to predict how much one variable changes when a second variable is changed. A regression equation may be formed, y = a + bx, where <br/><br/><ul><li>y = the variable being calculated </li><li>a = the intercept value, when x = 0 </li><li>b = the slope of the line or regression coefficient. Simply put, how much y changes for a given change in x </li><li>x = the second variable </li></ul><br/><b>Scatter graphs</b><br/><br/>Scatter graphs are used in correlation and regression analyses.  They assist in determining, visually, if variables are associated. They may also show the nature of a relationship. They can also assist in determining if there are any outliers that may be effecting the distribution.<br/><br/>When constructing a scatter graph it is conventional to put the dependent variable on the vertical axis and the independent variable on the horizontal axis. <br/><br/>The following graphs illustrate the different types of correlation you need to be familiar with: <br/><br/>Positive linear correlation (below)<br/><br/><center><table><tbody><tr><td align="left" colspan="2"><img class="ajaximage" src="https://d3a7z3xcyhqwt4.cloudfront.net/images_MRCPsychmentor/mma052.png"/></td></tr><tr><td align="left" valign="top"></td><td align="right"></td></tr></tbody></table></center><br/>Negative linear correlation <br/><br/><center><table><tbody><tr><td align="left" colspan="2"><img class="ajaximage" src="https://d3a7z3xcyhqwt4.cloudfront.net/images_MRCPsychmentor/mma046.png"/></td></tr><tr><td align="left" valign="top"></td><td align="right"></td></tr></tbody></table></center><br/>Non-linear (aka curvilinear) correlation <br/><br/><center><table><tbody><tr><td align="left" colspan="2"><img class="ajaximage" src="https://d3a7z3xcyhqwt4.cloudfront.net/images_MRCPsychmentor/mma047.png"/></td></tr><tr><td align="left" valign="top"></td><td align="right"></td></tr></tbody></table></center><br/>No correlation (aka independent)<br/><br/><center><table><tbody><tr><td align="left" colspan="2"><img class="ajaximage" src="https://d3a7z3xcyhqwt4.cloudfront.net/images_MRCPsychmentor/mma048.png"/></td></tr><tr><td align="left" valign="top"></td><td align="right"></td></tr></tbody></table></center><br/>Strong positive linear association <br/><br/><center><table><tbody><tr><td align="left" colspan="2"><img class="ajaximage" src="https://d3a7z3xcyhqwt4.cloudfront.net/images_MRCPsychmentor/mma049.png"/></td></tr><tr><td align="left" valign="top"></td><td align="right"></td></tr></tbody></table></center><br/>Weak positive linear association <br/><br/><center><table><tbody><tr><td align="left" colspan="2"><img class="ajaximage" src="https://d3a7z3xcyhqwt4.cloudfront.net/images_MRCPsychmentor/mma050.png"/></td></tr><tr><td align="left" valign="top"></td><td align="right"></td></tr></tbody></table></center><br/>An outlier is defined as a data point that emanates from a different model than do the rest of the data. The data (on the scatter graph below) appear to come from a linear model with a given line except for the outliers (Italy and to a lesser extent Spain) which appear to have been generated from some other model.<br/><br/><center><table><tbody><tr><td align="left" colspan="2"><img class="ajaximage" src="https://d3a7z3xcyhqwt4.cloudfront.net/images_MRCPsychmentor/mma010.png"/></td></tr><tr><td align="left" valign="top"></td><td align="right"></td></tr></tbody></table></center><br/>When constructing a scatter graph it is conventional to put the dependent variable on the vertical axis and the independent variable on the horizontal axis.<br/><br/>References:<br/><br/><i>Campbell (2021) Statistics at Square One. London: BMJ, 2021.</i></div></div>