<div id="div_question"><link href="style1.css" rel="stylesheet"/>Which of the following is a recognised type of reliability?<br/><div><br/><span style="background-color: #A5FF7F; padding: 11px 22px; border-radius: 4px; border-left: 5px solid green;">Inter-rater</span></div><br/>The correct answer is <b>Inter-rater</b>. Inter-rater reliability is a type of reliability that measures the extent to which different observers or raters consistently assess the same phenomenon. For example, in a clinical setting, if two psychiatrists independently evaluate the same patient's symptoms and come to similar conclusions, this demonstrates strong inter-rater reliability. This is crucial in ensuring that psychiatric diagnoses and assessments are consistent, regardless of who performs them.<br/><br/><b>Face</b>: Face validity is not a type of reliability; it refers to whether a test appears to measure what it is supposed to measure at face value. While important for test design, face validity does not relate to consistency or reliability.<br/><br/><b>Predictive</b>: Predictive validity refers to the extent to which a test can predict future outcomes or behaviour, such as using cognitive tests to predict future academic performance. It is related to validity, not reliability, and therefore is not a recognised type of reliability.<br/><br/><b>Concurrent</b>: Concurrent validity measures how well a new test compares to a well-established test administered at the same time. This is a type of validity, not reliability, and concerns whether two different tools produce similar results, rather than the consistency of the same tool.<br/><br/><b>Criterion</b>: Criterion validity is a form of validity, not reliability. It assesses whether a test reflects a certain set of abilities or outcomes by comparing it to an external criterion. For example, comparing a new depression scale to an established gold-standard measure. It does not measure consistency, which is what reliability assesses.<br/></div>